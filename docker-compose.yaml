version: "3.8"
services:
  triton_transformer:
    command:
      [
        "--model-repository=/models",
        "--log-info=1",
        "--min-supported-compute-capability=5.0",
      ]
    build: .
    shm_size: "2gb"
    restart: unless-stopped
    ports:
      - 8500:8000
      - 8501:8001
      - 8502:8002
    volumes:
      - ./:/workspace
      - ./model_repository:/models
      - ./models:/assets
    environment:
      - LC_ALL=C.UTF-8
      - LANG=C.UTF-8
    deploy:
      resources:
        limits:
          cpus: "1"
        # reservations:
        #   devices:
        #     - driver: nvidia
        #       device_ids: ["0"]
        #       capabilities: [gpu]
